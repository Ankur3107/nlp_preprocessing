{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_preprocessing import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nlp_preprocessing.clean' from '/Users/ankur.kumar/Desktop/Personal/Projects/git projects/nlp_preprocessing/nlp_preprocessing/clean.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Lowering everything:\n",
      "########## Step - Normalize chars and dots:\n",
      "########## Step - Remove hrefs:\n",
      "########## Step - Control Chars:\n",
      "########## Step - Duplicated Chars:\n",
      "Total Words : 4\n",
      "########## Step - Remove underscore:\n",
      "Total Words : 4\n",
      "[\"hi i am's nakdur\"]\n",
      "########## Step - Spam chars repetition:\n",
      "Total Words : 4\n",
      "{}\n",
      "########## Step - Brackets and quotes:\n",
      "########## Step - Break long words:\n",
      "########## Step - Break long words:\n",
      "########## Step - Remove ending underscore:\n",
      "Total Words : 4\n",
      "########## Step - Remove starting underscore:\n",
      "Total Words : 4\n",
      "########## Step - End word punctuations:\n",
      "########## Step - Start word punctuations:\n",
      "########## Step - Contractions:\n",
      "Total Words : 4\n",
      "########## Step - Remove \"s:\n",
      "Total Words : 4\n",
      "am's --- am\n",
      "########## Step - Isolate numbers:\n",
      "Total Words : 4\n",
      "Total Words : 4\n",
      "########## Step - L33T (with vocab check):\n",
      "Total Words : 4\n",
      "########## Step - Open Holded words:\n",
      "########## Step - Multiple form:\n",
      "Total Words : 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hi i am nakdur']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.clean_v1([\"Hi I am's nakdur\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_preprocessing import dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am Test 1</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am Test 2</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am Test 1</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am Test 2</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am Test 1</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am Test 2</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I am Test 1</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I am Test 2</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I am Test 1</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I am Test 2</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text label aspect\n",
       "0  I am Test 1     A      C\n",
       "1  I am Test 2     B      D\n",
       "2  I am Test 1     A      C\n",
       "3  I am Test 2     B      D\n",
       "4  I am Test 1     A      C\n",
       "5  I am Test 2     B      D\n",
       "6  I am Test 1     A      C\n",
       "7  I am Test 2     B      D\n",
       "8  I am Test 1     A      C\n",
       "9  I am Test 2     B      D"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['I am Test 1','I am Test 2']\n",
    "label = ['A','B']\n",
    "aspect = ['C','D']\n",
    "data = pd.DataFrame({'text':text*5,'label':label*5,'aspect':aspect*5})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "                'data_class':'multi-class',\n",
    "                'x_columns':['text','aspect'],\n",
    "                'y_columns':['label'],\n",
    "                'one_hot_encoded_columns':[],\n",
    "                'label_encoded_columns':['label','aspect'],\n",
    "                'data':data,\n",
    "                'split_ratio':0.2\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.Dataset(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_class': 'multi-class',\n",
       " 'x_columns': ['text', 'aspect'],\n",
       " 'y_columns': ['label'],\n",
       " 'one_hot_encoded_columns': [],\n",
       " 'label_encoded_columns': ['label', 'aspect'],\n",
       " 'data':           text label aspect\n",
       " 0  I am Test 1     A      C\n",
       " 1  I am Test 2     B      D\n",
       " 2  I am Test 1     A      C\n",
       " 3  I am Test 2     B      D\n",
       " 4  I am Test 1     A      C\n",
       " 5  I am Test 2     B      D\n",
       " 6  I am Test 1     A      C\n",
       " 7  I am Test 2     B      D\n",
       " 8  I am Test 1     A      C\n",
       " 9  I am Test 2     B      D,\n",
       " 'split_ratio': 0.2,\n",
       " 'random_state': 3107}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dataset.get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'label': array([0, 1, 1, 0, 0, 1, 0, 1])},\n",
       " {'text': array(['I am Test 1', 'I am Test 2', 'I am Test 2', 'I am Test 1',\n",
       "         'I am Test 1', 'I am Test 2', 'I am Test 1', 'I am Test 2'],\n",
       "        dtype=object), 'aspect': array([0, 1, 1, 0, 0, 1, 0, 1])})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Y_train'],train['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'label': array([0, 1])},\n",
       " {'text': array(['I am Test 1', 'I am Test 2'], dtype=object),\n",
       "  'aspect': array([0, 1])})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Y_test'],test['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_preprocessing import seq_token_generator as seq_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['I am Test 2', 'I am Test 1', 'I am Test 1', 'I am Test 1',\n",
    "         'I am Test 1', 'I am Test 2', 'I am Test 1', 'I am Test 2',\n",
    "         'I am Test 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 17.77it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = seq_gen.get_word_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 2, 3, 4],\n",
       "       [0, 0, 0, ..., 2, 3, 5],\n",
       "       [0, 0, 0, ..., 2, 3, 5],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 2, 3, 5],\n",
       "       [0, 0, 0, ..., 2, 3, 4],\n",
       "       [0, 0, 0, ..., 2, 3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_preprocessing.clean import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_list = ['to_lower', 'to_normalize', 'remove_href', 'remove_control_char','remove_duplicate', 'remove_underscore', \\\n",
    "'seperate_spam_chars', 'seperate_brakets_quotes','break_short_words', 'break_long_words', \\\n",
    "'remove_ending_underscore', 'remove_starting_underscore', 'seperate_end_word_punctuations','seperate_start_word_punctuations', \\\n",
    "'clean_contractions', 'remove_s', 'isolate_numbers', 'regex_split_word', 'leet_clean', 'clean_open_holded_words', 'clean_multiple_form']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Lowering everything:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['h', 'i']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLEAN_FUNS[clean_list[0]]('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['Hi how are you', \"I am's good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Lowering everything:\n",
      "########## Step - Normalize chars and dots:\n",
      "########## Step - Remove hrefs:\n",
      "########## Step - Control Chars:\n",
      "########## Step - Duplicated Chars:\n",
      "Total Words : 7\n",
      "########## Step - Remove underscore:\n",
      "Total Words : 7\n",
      "['hi how are you']\n",
      "########## Step - Spam chars repetition:\n",
      "Total Words : 7\n",
      "{}\n",
      "########## Step - Brackets and quotes:\n",
      "########## Step - Break long words:\n",
      "########## Step - Break long words:\n",
      "########## Step - Remove ending underscore:\n",
      "Total Words : 7\n",
      "########## Step - Remove starting underscore:\n",
      "Total Words : 7\n",
      "########## Step - End word punctuations:\n",
      "########## Step - Start word punctuations:\n",
      "########## Step - Contractions:\n",
      "Total Words : 7\n",
      "########## Step - Remove \"s:\n",
      "Total Words : 7\n",
      "am's --- am\n",
      "########## Step - Isolate numbers:\n",
      "Total Words : 7\n",
      "Total Words : 7\n",
      "########## Step - L33T (with vocab check):\n",
      "Total Words : 7\n",
      "########## Step - Open Holded words:\n",
      "########## Step - Multiple form:\n",
      "Total Words : 7\n"
     ]
    }
   ],
   "source": [
    "cleaned_texts = Clean()(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi how are you', 'i am good']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ([1],[2],[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict={'VERB': 0,\n",
    "  'NOUN': 1,\n",
    "  'ADP': 2,\n",
    "  'SCONJ': 3,\n",
    "  'SYM': 4,\n",
    "  'CCONJ': 5,\n",
    "  'SPACE': 6,\n",
    "  'X': 7,\n",
    "  'PUNCT': 8,\n",
    "  'INTJ': 9,\n",
    "  'PROPN': 10,\n",
    "  'ADV': 11,\n",
    "  'AUX': 12,\n",
    "  'ADJ': 13,\n",
    "  'DET': 14,\n",
    "  'NUM': 15,\n",
    "  'PRON': 16,\n",
    "  'PART': 17}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict={'VBN': 0,\n",
    "  'RBR': 1,\n",
    "  'EX': 2,\n",
    "  '_SP': 3,\n",
    "  'VBD': 4,\n",
    "  'NN': 5,\n",
    "  'SYM': 6,\n",
    "  'RBS': 7,\n",
    "  ':': 8,\n",
    "  'NNS': 9,\n",
    "  'WP$': 10,\n",
    "  'UH': 11,\n",
    "  'JJR': 12,\n",
    "  '-RRB-': 13,\n",
    "  'CC': 14,\n",
    "  'VBZ': 15,\n",
    "  'TO': 16,\n",
    "  'PRP$': 17,\n",
    "  ',': 18,\n",
    "  'JJ': 19,\n",
    "  '-LRB-': 20,\n",
    "  'RB': 21,\n",
    "  'NNP': 22,\n",
    "  'DT': 23,\n",
    "  'RP': 24,\n",
    "  'VBG': 25,\n",
    "  \"''\": 26,\n",
    "  'WDT': 27,\n",
    "  'MD': 28,\n",
    "  'FW': 29,\n",
    "  'CD': 30,\n",
    "  'PRP': 31,\n",
    "  'JJS': 32,\n",
    "  'VB': 33,\n",
    "  'WP': 34,\n",
    "  'LS': 35,\n",
    "  'XX': 36,\n",
    "  'AFX': 37,\n",
    "  'WRB': 38,\n",
    "  'HYPH': 39,\n",
    "  'POS': 40,\n",
    "  'VBP': 41,\n",
    "  'NFP': 42,\n",
    "  '``': 43,\n",
    "  'NNPS': 44,\n",
    "  'PDT': 45,\n",
    "  '.': 46,\n",
    "  'IN': 47}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_dict={'nsubj': 0,\n",
    "  '': 1,\n",
    "  'advcl': 2,\n",
    "  'prep': 3,\n",
    "  'relcl': 4,\n",
    "  'intj': 5,\n",
    "  'ccomp': 6,\n",
    "  'amod': 7,\n",
    "  'appos': 8,\n",
    "  'prt': 9,\n",
    "  'nmod': 10,\n",
    "  'aux': 11,\n",
    "  'xcomp': 12,\n",
    "  'csubjpass': 13,\n",
    "  'case': 14,\n",
    "  'pobj': 15,\n",
    "  'oprd': 16,\n",
    "  'nummod': 17,\n",
    "  'punct': 18,\n",
    "  'compound': 19,\n",
    "  'attr': 20,\n",
    "  'advmod': 21,\n",
    "  'meta': 22,\n",
    "  'poss': 23,\n",
    "  'parataxis': 24,\n",
    "  'dative': 25,\n",
    "  'cc': 26,\n",
    "  'acomp': 27,\n",
    "  'neg': 28,\n",
    "  'dobj': 29,\n",
    "  'agent': 30,\n",
    "  'quantmod': 31,\n",
    "  'det': 32,\n",
    "  'auxpass': 33,\n",
    "  'mark': 34,\n",
    "  'pcomp': 35,\n",
    "  'expl': 36,\n",
    "  'nsubjpass': 37,\n",
    "  'npadvmod': 38,\n",
    "  'acl': 39,\n",
    "  'conj': 40,\n",
    "  'predet': 41,\n",
    "  'csubj': 42,\n",
    "  'dep': 43,\n",
    "  'preconj': 44,\n",
    "  'ROOT': 45}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PAD]': 0,\n",
       " 'nsubj': 1,\n",
       " '': 2,\n",
       " 'advcl': 3,\n",
       " 'prep': 4,\n",
       " 'relcl': 5,\n",
       " 'intj': 6,\n",
       " 'ccomp': 7,\n",
       " 'amod': 8,\n",
       " 'appos': 9,\n",
       " 'prt': 10,\n",
       " 'nmod': 11,\n",
       " 'aux': 12,\n",
       " 'xcomp': 13,\n",
       " 'csubjpass': 14,\n",
       " 'case': 15,\n",
       " 'pobj': 16,\n",
       " 'oprd': 17,\n",
       " 'nummod': 18,\n",
       " 'punct': 19,\n",
       " 'compound': 20,\n",
       " 'attr': 21,\n",
       " 'advmod': 22,\n",
       " 'meta': 23,\n",
       " 'poss': 24,\n",
       " 'parataxis': 25,\n",
       " 'dative': 26,\n",
       " 'cc': 27,\n",
       " 'acomp': 28,\n",
       " 'neg': 29,\n",
       " 'dobj': 30,\n",
       " 'agent': 31,\n",
       " 'quantmod': 32,\n",
       " 'det': 33,\n",
       " 'auxpass': 34,\n",
       " 'mark': 35,\n",
       " 'pcomp': 36,\n",
       " 'expl': 37,\n",
       " 'nsubjpass': 38,\n",
       " 'npadvmod': 39,\n",
       " 'acl': 40,\n",
       " 'conj': 41,\n",
       " 'predet': 42,\n",
       " 'csubj': 43,\n",
       " 'dep': 44,\n",
       " 'preconj': 45,\n",
       " 'ROOT': 46}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(['[PAD]']+list(dep_dict.keys()), list(range(47))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_preprocessing.seq_parser_token_generator_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ParserTokenization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 14.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pos': [['INTJ', 'ADV', 'AUX', 'PRON']],\n",
       " 'tag': [['UH', 'WRB', 'VBP', 'PRP']],\n",
       " 'dep': [['intj', 'advmod', 'ROOT', 'nsubj']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.tokenizer(['Hi how are you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 71.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pos': [[10, 12, 13, 17, 0, 0, 0, 0, 0, 0]],\n",
       " 'tag': [[12, 39, 42, 32, 0, 0, 0, 0, 0, 0]],\n",
       " 'dep': [[6, 22, 46, 1, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.encode_plus(['Hi how are you'], max_seq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTJ',\n",
       " 'ADV',\n",
       " 'AUX',\n",
       " 'PRON',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.convert_ids_to_tokens([10, 12, 13, 17, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': [10, 12, 13, 17, 0, 0, 0, 0, 0, 0],\n",
       " 'tag': [12, 39, 42, 32, 0, 0, 0, 0, 0, 0],\n",
       " 'dep': [6, 22, 46, 1, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.encode('hi how are you', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': [10, 12, 13, 17, 0, 0, 0, 0, 0, 0],\n",
       " 'tag': [12, 39, 42, 32, 0, 0, 0, 0, 0, 0],\n",
       " 'dep': [6, 22, 46, 1, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser('hi how are you', max_seq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 61.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pos': [[10, 12, 13, 17, 0, 0, 0, 0, 0, 0]],\n",
       " 'tag': [[12, 39, 42, 32, 0, 0, 0, 0, 0, 0]],\n",
       " 'dep': [[6, 22, 46, 1, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser(['hi how are you'],'encode_plus', max_seq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 57.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pos': [['INTJ', 'ADV', 'AUX', 'PRON']],\n",
       " 'tag': [['UH', 'WRB', 'VBP', 'PRP']],\n",
       " 'dep': [['intj', 'advmod', 'ROOT', 'nsubj']]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser(['hi how are you'],'tokenizer', max_seq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_preprocessing.seq_token_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacytokenizer = SpacyTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Hi', 'how', 'are', 'you']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacytokenizer.tokenize(['Hi how are you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PAD]': 0, 'Hi': 1, 'how': 2, 'are': 3, 'you': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacytokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacytokenizer.encode('Hi how are you', max_seq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 40.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacytokenizer.encode_plus(['Hi how are you'], max_seq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Hi', 'how', 'are', 'you']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacytokenizer = SpacyTokenizer()\n",
    "spacytokenizer.tokenize(['Hi how are you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacytokenizer.encode('Hi how are you', max_seq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 45.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacytokenizer.encode_plus(['Hi how are you'], max_seq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacytokenizer = SpacyTokenizer()\n",
    "spacytokenizer('Hi how are you', 'encode', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_preprocessing.tokenization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(vocab_file='/Users/ankur.kumar/Downloads/BERT_LARGE_DIR/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7632, 28954, 2072]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize('hiiiii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', '##iii', '##z']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('hiiiiz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2480"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['##z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('tf2_env': venv)",
   "language": "python",
   "name": "python37564bittf2envvenv9baad5f63bf544adb456767f347f0830"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
