```python
from nbdev.showdoc import *
```


```python
from nlp_preprocessing import *
```


```python
show_doc(validate_case_matches_checkpoint)
```


<h4 id="validate_case_matches_checkpoint" class="doc_header"><code>validate_case_matches_checkpoint</code><a href="nlp_preprocessing/tokenization.py#L11" class="source_link" style="float:right">[source]</a></h4>

> <code>validate_case_matches_checkpoint</code>(**`do_lower_case`**, **`init_checkpoint`**)

Checks whether the casing config is consistent with the checkpoint name.



```python
show_doc(SpacyParseTokenizer)
```


<h2 id="SpacyParseTokenizer" class="doc_header"><code>class</code> <code>SpacyParseTokenizer</code><a href="nlp_preprocessing/seq_parser_token_generator.py#L142" class="source_link" style="float:right">[source]</a></h2>

> <code>SpacyParseTokenizer</code>(**`parsers`**=*`['pos', 'tag', 'dep']`*)





```python
show_doc(SpacyTokenizer)
```


<h2 id="SpacyTokenizer" class="doc_header"><code>class</code> <code>SpacyTokenizer</code><a href="nlp_preprocessing/seq_token_generator.py#L40" class="source_link" style="float:right">[source]</a></h2>

> <code>SpacyTokenizer</code>(**`vocab_file`**=*`None`*, **`spacy_tokenizer`**=*`<spacy.tokenizer.Tokenizer object at 0x15f14ab50>`*, **`special_token`**=*`['[PAD]']`*, **`pad_token_index`**=*`0`*)





```python

```


```python

```
