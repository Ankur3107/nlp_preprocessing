<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Tokenization - nlp-preprocessing</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../css/theme.css" />
  <link rel="stylesheet" href="../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Tokenization";
    var mkdocs_page_input_path = "tokenization.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> nlp-preprocessing</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../cleaning/">Cleaning</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../dataset/">Dataset</a>
                    </li>
                </ul>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Tokenization</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../vocab_embedding_extractor/">Vocab & Embedding Extractor</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">nlp-preprocessing</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Tokenization</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <pre><code class="python">from nlp_preprocessing.seq_token_generator import *
</code></pre>

<p><code>SpacyTokenizer</code> allow to tokenize your text. <code>__call__</code> method can </p>
<h2 id="SpacyTokenizer" class="doc_header"><code>class</code> <code>SpacyTokenizer</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_token_generator.py#L40" class="source_link" style="float:right">[source]</a></h2>

<blockquote>
<p><code>SpacyTokenizer</code>(<strong><code>vocab_file</code></strong>=<em><code>None</code></em>, <strong><code>spacy_tokenizer</code></strong>=<em><code>&lt;spacy.tokenizer.Tokenizer object at 0x167c88950&gt;</code></em>, <strong><code>special_token</code></strong>=<em><code>['[PAD]']</code></em>, <strong><code>pad_token_index</code></strong>=<em><code>0</code></em>)</p>
</blockquote>
<h4 id="SpacyTokenizer.__call__" class="doc_header"><code>SpacyTokenizer.__call__</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_token_generator.py#L150" class="source_link" style="float:right">[source]</a></h4>

<blockquote>
<p><code>SpacyTokenizer.<strong>call</strong></code>(<strong><code>inputs</code></strong>, <strong><code>call_type</code></strong>=<em><code>'tokenize'</code></em>, <strong><code>max_seq</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p><code>__call__</code> method allow to call encode, encode_plus and tokenize from single interface.</p>
<p>Args:</p>
<pre><code>inputs (List or string): Input can be string or list of text

call_type (str, optional): can be encode, encode_plus, tokenize. Defaults to 'tokenize'.

max_seq ([type], optional): it applies for encode and encode_plus call_type Defaults to None (for tokenzie call_type).
</code></pre>
<p>Returns:</p>
<pre><code>tokens or ids: List or List of List
</code></pre>
<h4 id="SpacyTokenizer.encode" class="doc_header"><code>SpacyTokenizer.encode</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_token_generator.py#L95" class="source_link" style="float:right">[source]</a></h4>

<blockquote>
<p><code>SpacyTokenizer.encode</code>(<strong><code>text</code></strong>, <strong><code>max_seq</code></strong>=<em><code>128</code></em>)</p>
</blockquote>
<p><code>encode</code> method allow to encode text into ids with max_seq lenght</p>
<p>Args:</p>
<pre><code>text (string): input text

max_seq (int, optional): Defaults to 128.
</code></pre>
<p>Returns:</p>
<pre><code>tokens: List of token
</code></pre>
<h4 id="SpacyTokenizer.encode_plus" class="doc_header"><code>SpacyTokenizer.encode_plus</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_token_generator.py#L120" class="source_link" style="float:right">[source]</a></h4>

<blockquote>
<p><code>SpacyTokenizer.encode_plus</code>(<strong><code>input_texts</code></strong>, <strong><code>max_seq</code></strong>=<em><code>128</code></em>)</p>
</blockquote>
<p><code>encode_plus</code> method allow to encode list of text into list of ids with max_seq lenght</p>
<p>Args:</p>
<pre><code>input_texts (List): List of text

max_seq (int, optional): Defaults to 128.
</code></pre>
<p>Returns:</p>
<pre><code>tokens: List of List of token
</code></pre>
<h4 id="SpacyTokenizer.tokenize" class="doc_header"><code>SpacyTokenizer.tokenize</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_token_generator.py#L60" class="source_link" style="float:right">[source]</a></h4>

<blockquote>
<p><code>SpacyTokenizer.tokenize</code>(<strong><code>input_texts</code></strong>)</p>
</blockquote>
<p><code>tokenizer</code> method allow to tokenize text</p>
<p>Args:</p>
<pre><code>input_texts (List): Takes list of text(string)
</code></pre>
<p>Returns:</p>
<pre><code>tokens: List[List]
</code></pre>
<p>Examples</p>
<pre><code class="python">texts = ['Hi, how are you', &quot;I am good&quot;]
tokens = SpacyTokenizer()(texts, call_type='tokenize')
print('Output :',tokens)
</code></pre>

<pre><code>2it [00:00,  4.64it/s]

Output : [['Hi', ',', 'how', 'are', 'you'], ['I', 'am', 'good']]
</code></pre>
<pre><code class="python">texts = ['Hi, how are you', &quot;I am good&quot;]
spacy_tokenizer = SpacyTokenizer()
tokens = spacy_tokenizer.tokenize(texts)
ids =  [spacy_tokenizer.convert_tokens_to_ids(token) for token in tokens]
print('Tokens : ',tokens)
print('Token_ids : ', ids)
print('Vocab : ', spacy_tokenizer.vocab)
</code></pre>

<pre><code>2it [00:00, 79.79it/s]

Tokens :  [['Hi', ',', 'how', 'are', 'you'], ['I', 'am', 'good']]
Token_ids :  [[1, 2, 3, 4, 5], [6, 7, 8]]
Vocab :  {'[PAD]': 0, 'Hi': 1, ',': 2, 'how': 3, 'are': 4, 'you': 5, 'I': 6, 'am': 7, 'good': 8}
</code></pre>
<pre><code class="python">texts = ['Hi, how are you', &quot;I am good&quot;]
spacy_tokenizer = SpacyTokenizer()
ids = spacy_tokenizer.encode_plus(texts, max_seq=10)
print('Token_ids : ', ids)
print('Vocab : ', spacy_tokenizer.vocab)
</code></pre>

<pre><code>2it [00:00, 80.31it/s]

Token_ids :  [[1, 2, 3, 4, 5, 0, 0, 0, 0, 0], [6, 7, 8, 0, 0, 0, 0, 0, 0, 0]]
Vocab :  {'[PAD]': 0, 'Hi': 1, ',': 2, 'how': 3, 'are': 4, 'you': 5, 'I': 6, 'am': 7, 'good': 8}
</code></pre>
<pre><code class="python">spacy_tokenizer = SpacyTokenizer()
ids = spacy_tokenizer.encode('Hi, how are you', max_seq=10)
print('Token Ids :', ids)
print('Vocab : ', spacy_tokenizer.vocab)
</code></pre>

<pre><code>Token Ids : [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]
Vocab :  {'[PAD]': 0, 'Hi': 1, ',': 2, 'how': 3, 'are': 4, 'you': 5}
</code></pre>
<pre><code class="python">from nlp_preprocessing.seq_parser_token_generator import *
</code></pre>

<p><code>SpacyParseTokenizer</code> allow to tokenize text and get different parse tokens i.e. dependency parse, tag parse, pos parse from Spacy model </p>
<h2 id="SpacyParseTokenizer" class="doc_header"><code>class</code> <code>SpacyParseTokenizer</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_parser_token_generator.py#L142" class="source_link" style="float:right">[source]</a></h2>

<blockquote>
<p><code>SpacyParseTokenizer</code>(<strong><code>parsers</code></strong>=<em><code>['pos', 'tag', 'dep']</code></em>)</p>
</blockquote>
<h4 id="SpacyParseTokenizer.__call__" class="doc_header"><code>SpacyParseTokenizer.__call__</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_parser_token_generator.py#L163" class="source_link" style="float:right">[source]</a></h4>

<blockquote>
<p><code>SpacyParseTokenizer.<strong>call</strong></code>(<strong><code>inputs</code></strong>, <strong><code>call_type</code></strong>=<em><code>'tokenize'</code></em>, <strong><code>max_seq</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p><code>__call__</code> method allow a single interface to call encode, encode_plus and tokenize methods</p>
<p>Args:</p>
<pre><code>inputs (List or string): It can be string (for encode call type) or List for encode_plus and tokenize

call_type (str, optional): can be encode, encode_plus, tokenize. Defaults to 'tokenize'.

max_seq ([type], optional): it applies for encode and encode_plus call_type Defaults to None (for tokenzie call_type).
</code></pre>
<p>Returns:
    results: dict (contains keys i.e. tag, pos, dep)</p>
<h4 id="SpacyParseTokenizer.tokenize" class="doc_header"><code>SpacyParseTokenizer.tokenize</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_parser_token_generator.py#L282" class="source_link" style="float:right">[source]</a></h4>

<blockquote>
<p><code>SpacyParseTokenizer.tokenize</code>(<strong><code>input_texts</code></strong>)</p>
</blockquote>
<p><code>tokenizer</code> method allow to tokenize text</p>
<p>Args:</p>
<pre><code>input_texts (List): Takes list of text(string)
</code></pre>
<p>Returns:</p>
<pre><code>results: dict
</code></pre>
<h4 id="SpacyParseTokenizer.encode" class="doc_header"><code>SpacyParseTokenizer.encode</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_parser_token_generator.py#L195" class="source_link" style="float:right">[source]</a></h4>

<blockquote>
<p><code>SpacyParseTokenizer.encode</code>(<strong><code>text</code></strong>, <strong><code>max_seq</code></strong>=<em><code>128</code></em>)</p>
</blockquote>
<p><code>encode</code> method allow to encode text into ids with max_seq lenght</p>
<p>Args:</p>
<pre><code>text (string): input text

max_seq (int, optional): Defaults to 128.
</code></pre>
<p>Returns:</p>
<pre><code>results: dict
</code></pre>
<h4 id="SpacyParseTokenizer.encode_plus" class="doc_header"><code>SpacyParseTokenizer.encode_plus</code><a href="https://github.com/Ankur3107/nlp_preprocessing/blob/master/nlp_preprocessing/seq_parser_token_generator.py#L230" class="source_link" style="float:right">[source]</a></h4>

<blockquote>
<p><code>SpacyParseTokenizer.encode_plus</code>(<strong><code>input_texts</code></strong>, <strong><code>max_seq</code></strong>=<em><code>128</code></em>)</p>
</blockquote>
<p><code>encode_plus</code> method allow to encode list of text into list of ids with max_seq lenght</p>
<p>Args:</p>
<pre><code>input_texts (List): List of text

max_seq (int, optional): Defaults to 128.
</code></pre>
<p>Returns:</p>
<pre><code>results: dict
</code></pre>
<p>Examples</p>
<pre><code class="python">texts = ['Hi, how are you', &quot;I am good&quot;]
tokens = SpacyParseTokenizer()(texts, call_type='tokenize')
print('Output :',tokens)
</code></pre>

<pre><code>2it [00:00, 51.19it/s]

Output : {'pos': [['INTJ', 'PUNCT', 'ADV', 'AUX', 'PRON'], ['PRON', 'AUX', 'ADJ']], 'tag': [['UH', ',', 'WRB', 'VBP', 'PRP'], ['PRP', 'VBP', 'JJ']], 'dep': [['intj', 'punct', 'advmod', 'ROOT', 'nsubj'], ['nsubj', 'ROOT', 'acomp']]}
</code></pre>
<pre><code class="python">texts = ['Hi, how are you', &quot;I am good&quot;]
tokens = SpacyTokenizer()(texts, call_type='tokenize')
parse_tokens = SpacyParseTokenizer()(texts, call_type='tokenize')
print('Output : ',tokens)
print('Parse Dict : ', parse_tokens)
</code></pre>

<pre><code>2it [00:00, 70.61it/s]
2it [00:00, 54.82it/s]

Output :  [['Hi', ',', 'how', 'are', 'you'], ['I', 'am', 'good']]
Parse Dict :  {'pos': [['INTJ', 'PUNCT', 'ADV', 'AUX', 'PRON'], ['PRON', 'AUX', 'ADJ']], 'tag': [['UH', ',', 'WRB', 'VBP', 'PRP'], ['PRP', 'VBP', 'JJ']], 'dep': [['intj', 'punct', 'advmod', 'ROOT', 'nsubj'], ['nsubj', 'ROOT', 'acomp']]}
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../vocab_embedding_extractor/" class="btn btn-neutral float-right" title="Vocab & Embedding Extractor">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../dataset/" class="btn btn-neutral" title="Dataset"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../dataset/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../vocab_embedding_extractor/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
